{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "hjO9f4gnIoCf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hjO9f4gnIoCf",
    "outputId": "e789306e-f32e-4843-e621-b7742b27d293",
    "ExecuteTime": {
     "end_time": "2024-07-08T19:03:39.016604400Z",
     "start_time": "2024-07-08T19:03:12.489710500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import segmentation_models_pytorch as smp\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "folder_path = \"МЫШИПТУ\"\n",
    "\n",
    "seed_value = 52\n",
    "torch.manual_seed(seed_value)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12ef3ad3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T19:10:00.252757Z",
     "start_time": "2024-07-08T19:10:00.231759100Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_csv_files(folder_path, folder):\n",
    "    images_folder = folder_path + \"/\" + folder + \"images\"\n",
    "    masks_folder = folder_path + \"/\" + folder + \"masks\"\n",
    "\n",
    "    images_files = os.listdir(images_folder)\n",
    "    masks_files = os.listdir(masks_folder)\n",
    "\n",
    "    image_paths = [os.path.join(folder + \"images\", file) for file in images_files]\n",
    "    mask_paths = [os.path.join(folder + \"masks\", file) for file in masks_files]\n",
    "\n",
    "    data = {'orig_image': image_paths, 'mask_image': mask_paths}\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    csv_file_path = \"mouse_final/train_data.csv\" if folder == \"\" else \"mouse_final/test_data.csv\"\n",
    "\n",
    "    df.to_csv(csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b1ab03e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T19:11:37.357006200Z",
     "start_time": "2024-07-08T19:11:37.313005300Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] Системе не удается найти указанный путь: 'mouse_final/МЫШИПТУ/test_images'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[17], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mmake_csv_files\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmouse_final/МЫШИПТУ\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtest_\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      2\u001B[0m make_csv_files(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmouse_final/МЫШИПТУ\u001B[39m\u001B[38;5;124m\"\u001B[39m,\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m      3\u001B[0m train_df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain_data.csv\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[1;32mIn[15], line 5\u001B[0m, in \u001B[0;36mmake_csv_files\u001B[1;34m(folder_path, folder)\u001B[0m\n\u001B[0;32m      2\u001B[0m images_folder \u001B[38;5;241m=\u001B[39m folder_path \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m folder \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mimages\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m      3\u001B[0m masks_folder \u001B[38;5;241m=\u001B[39m folder_path \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m folder \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmasks\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m----> 5\u001B[0m images_files \u001B[38;5;241m=\u001B[39m \u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlistdir\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimages_folder\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      6\u001B[0m masks_files \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mlistdir(masks_folder)\n\u001B[0;32m      8\u001B[0m image_paths \u001B[38;5;241m=\u001B[39m [os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(folder \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mimages\u001B[39m\u001B[38;5;124m\"\u001B[39m, file) \u001B[38;5;28;01mfor\u001B[39;00m file \u001B[38;5;129;01min\u001B[39;00m images_files]\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [WinError 3] Системе не удается найти указанный путь: 'mouse_final/МЫШИПТУ/test_images'"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"train_data.csv\")\n",
    "test = pd.read_csv(\"test_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Qp8AXKYe1GA0",
   "metadata": {
    "id": "Qp8AXKYe1GA0"
   },
   "source": [
    "### Preprocessing (подготовка данных)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "                                         orig_image  \\\n0  test_images\\OFT_control_01$000152&03_@000064.bmp   \n1  test_images\\OFT_control_01$000152&03_@004271.bmp   \n2  test_images\\OFT_control_02$000146&03_@000152.bmp   \n3  test_images\\OFT_control_02$000146&03_@004474.bmp   \n4  test_images\\OFT_control_03$000141&03_@000030.bmp   \n5  test_images\\OFT_control_03$000141&03_@004498.bmp   \n6  test_images\\OFT_control_04$000176&03_@000060.bmp   \n7  test_images\\OFT_control_04$000176&03_@004368.bmp   \n8  test_images\\OFT_control_05$000124&03_@000055.bmp   \n9  test_images\\OFT_control_05$000124&03_@003979.bmp   \n\n                                        mask_image  \n0  test_masks\\OFT_control_01$000152&03_@000064.bmp  \n1  test_masks\\OFT_control_01$000152&03_@004271.bmp  \n2  test_masks\\OFT_control_02$000146&03_@000152.bmp  \n3  test_masks\\OFT_control_02$000146&03_@004474.bmp  \n4  test_masks\\OFT_control_03$000141&03_@000030.bmp  \n5  test_masks\\OFT_control_03$000141&03_@004498.bmp  \n6  test_masks\\OFT_control_04$000176&03_@000060.bmp  \n7  test_masks\\OFT_control_04$000176&03_@004368.bmp  \n8  test_masks\\OFT_control_05$000124&03_@000055.bmp  \n9  test_masks\\OFT_control_05$000124&03_@003979.bmp  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>orig_image</th>\n      <th>mask_image</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>test_images\\OFT_control_01$000152&amp;03_@000064.bmp</td>\n      <td>test_masks\\OFT_control_01$000152&amp;03_@000064.bmp</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>test_images\\OFT_control_01$000152&amp;03_@004271.bmp</td>\n      <td>test_masks\\OFT_control_01$000152&amp;03_@004271.bmp</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>test_images\\OFT_control_02$000146&amp;03_@000152.bmp</td>\n      <td>test_masks\\OFT_control_02$000146&amp;03_@000152.bmp</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>test_images\\OFT_control_02$000146&amp;03_@004474.bmp</td>\n      <td>test_masks\\OFT_control_02$000146&amp;03_@004474.bmp</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>test_images\\OFT_control_03$000141&amp;03_@000030.bmp</td>\n      <td>test_masks\\OFT_control_03$000141&amp;03_@000030.bmp</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>test_images\\OFT_control_03$000141&amp;03_@004498.bmp</td>\n      <td>test_masks\\OFT_control_03$000141&amp;03_@004498.bmp</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>test_images\\OFT_control_04$000176&amp;03_@000060.bmp</td>\n      <td>test_masks\\OFT_control_04$000176&amp;03_@000060.bmp</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>test_images\\OFT_control_04$000176&amp;03_@004368.bmp</td>\n      <td>test_masks\\OFT_control_04$000176&amp;03_@004368.bmp</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>test_images\\OFT_control_05$000124&amp;03_@000055.bmp</td>\n      <td>test_masks\\OFT_control_05$000124&amp;03_@000055.bmp</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>test_images\\OFT_control_05$000124&amp;03_@003979.bmp</td>\n      <td>test_masks\\OFT_control_05$000124&amp;03_@003979.bmp</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-08T19:08:40.738314400Z",
     "start_time": "2024-07-08T19:08:40.657313700Z"
    }
   },
   "id": "408dca0d94645c79"
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "YtAjmVyknkeZ",
   "metadata": {
    "id": "YtAjmVyknkeZ",
    "ExecuteTime": {
     "end_time": "2024-07-08T16:47:23.662031200Z",
     "start_time": "2024-07-08T16:47:23.652028500Z"
    }
   },
   "outputs": [],
   "source": [
    "class ImagesDataset(Dataset):\n",
    "    def __init__(self, folder, data, transform_image, transform_mask):\n",
    "      self.folder = folder\n",
    "      self.data = data.copy()\n",
    "      self.orig_image_paths = [os.path.join(folder, filename) for filename in data['orig_image'].copy()]\n",
    "      self.mask_image_paths = [os.path.join(folder, filename) for filename in data['mask_image'].copy()]\n",
    "      self.transform_image = transform_image\n",
    "      self.transform_mask = transform_mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.orig_image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        orig_image_path = self.orig_image_paths[idx]\n",
    "        mask_image_path = self.mask_image_paths[idx]\n",
    "        orig_image = Image.open(orig_image_path).convert('RGB')\n",
    "        mask_image = Image.open(mask_image_path).convert('L')\n",
    "        \n",
    "        orig_image = self.transform_image(orig_image)\n",
    "        orig_image = orig_image.to(orig_image)\n",
    "        \n",
    "        mask_image = self.transform_mask(mask_image)\n",
    "        mask_image = mask_image.to(mask_image)\n",
    "        \n",
    "        return orig_image.float(), mask_image.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "QYSoz-zi1dxx",
   "metadata": {
    "id": "QYSoz-zi1dxx",
    "ExecuteTime": {
     "end_time": "2024-07-08T16:47:24.357556700Z",
     "start_time": "2024-07-08T16:47:24.318540300Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, val = train_test_split(train_df, test_size=0.1 , random_state=42)\n",
    "\n",
    "size = (320, 544)\n",
    "mean=[0.485, 0.456, 0.406]\n",
    "std=[0.229, 0.224, 0.225]\n",
    "batch_size = 8\n",
    "\n",
    "transform_image = transforms.Compose([transforms.Resize(size), transforms.ToTensor(), transforms.Normalize(mean=mean, std=std)])\n",
    "\n",
    "transform_mask = transforms.Compose([transforms.Resize(size), transforms.ToTensor()])\n",
    "\n",
    "train_dataset = ImagesDataset(folder_path, train, transform_image, transform_mask)\n",
    "val_dataset = ImagesDataset(folder_path, val, transform_image, transform_mask)\n",
    "test_dataset = ImagesDataset(folder_path, test, transform_image, transform_mask)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rrEV7VFN1_60",
   "metadata": {
    "id": "rrEV7VFN1_60"
   },
   "source": [
    "### Training/evaluation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "sDeneMzs7XOP",
   "metadata": {
    "id": "sDeneMzs7XOP",
    "ExecuteTime": {
     "end_time": "2024-07-08T16:47:26.674739Z",
     "start_time": "2024-07-08T16:47:26.184150Z"
    }
   },
   "outputs": [],
   "source": [
    "def iou_score(outputs, labels):\n",
    "    intersection = torch.logical_and(outputs, labels).sum()\n",
    "    union = torch.logical_or(outputs, labels).sum()\n",
    "    iou = (intersection + 1e-6) / (union + 1e-6)\n",
    "    return iou.item()\n",
    "\n",
    "def learning(num_epochs, train_load, val_load, model, optimizer, criterion, model_name, scheduler=None):\n",
    "    device = next(model.parameters()).device\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    iou_test = []\n",
    "    max_iou = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for x_batch, y_batch in tqdm(train_load):\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(x_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        train_losses.append(train_loss/len(train_load))\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step(train_loss)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            iou_epoch = 0\n",
    "            for x_batch, y_batch in tqdm(val_load):\n",
    "                x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "                outputs = model(x_batch)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                val_loss += loss.item()\n",
    "                iou = iou_score(outputs, y_batch)\n",
    "                iou_epoch += iou\n",
    "            val_losses.append(val_loss/len(val_load))\n",
    "            iou_test.append(iou_epoch/len(val_load))\n",
    "\n",
    "            if iou_test[-1] > max_iou:\n",
    "                max_iou = iou_test[-1]\n",
    "                torch.save(model.state_dict(), f'{model_name}_best.pth')\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}: Train Loss: {train_losses[-1]}, Val Loss: {val_losses[-1]}, IoU: {iou_test[-1]}\")\n",
    "\n",
    "    return model, train_losses, val_losses, iou_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4AFsMmyU2Dgx",
   "metadata": {
    "id": "4AFsMmyU2Dgx"
   },
   "source": [
    "### Prediction function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "l12xJx4g2G4w",
   "metadata": {
    "id": "l12xJx4g2G4w"
   },
   "source": [
    "### Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9206a08b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T16:47:30.578842700Z",
     "start_time": "2024-07-08T16:47:29.450078200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "UnetPlusPlus(\n  (encoder): EfficientNetEncoder(\n    (_conv_stem): Conv2dStaticSamePadding(\n      3, 48, kernel_size=(3, 3), stride=(2, 2), bias=False\n      (static_padding): ZeroPad2d((0, 1, 0, 1))\n    )\n    (_bn0): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n    (_blocks): ModuleList(\n      (0): MBConvBlock(\n        (_depthwise_conv): Conv2dStaticSamePadding(\n          48, 48, kernel_size=(3, 3), stride=[1, 1], groups=48, bias=False\n          (static_padding): ZeroPad2d((1, 1, 1, 1))\n        )\n        (_bn1): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_se_reduce): Conv2dStaticSamePadding(\n          48, 12, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_se_expand): Conv2dStaticSamePadding(\n          12, 48, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_project_conv): Conv2dStaticSamePadding(\n          48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_swish): MemoryEfficientSwish()\n      )\n      (1): MBConvBlock(\n        (_depthwise_conv): Conv2dStaticSamePadding(\n          24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False\n          (static_padding): ZeroPad2d((1, 1, 1, 1))\n        )\n        (_bn1): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_se_reduce): Conv2dStaticSamePadding(\n          24, 6, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_se_expand): Conv2dStaticSamePadding(\n          6, 24, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_project_conv): Conv2dStaticSamePadding(\n          24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_swish): MemoryEfficientSwish()\n      )\n      (2): MBConvBlock(\n        (_expand_conv): Conv2dStaticSamePadding(\n          24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_depthwise_conv): Conv2dStaticSamePadding(\n          144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False\n          (static_padding): ZeroPad2d((0, 1, 0, 1))\n        )\n        (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_se_reduce): Conv2dStaticSamePadding(\n          144, 6, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_se_expand): Conv2dStaticSamePadding(\n          6, 144, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_project_conv): Conv2dStaticSamePadding(\n          144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_swish): MemoryEfficientSwish()\n      )\n      (3-5): 3 x MBConvBlock(\n        (_expand_conv): Conv2dStaticSamePadding(\n          32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_depthwise_conv): Conv2dStaticSamePadding(\n          192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False\n          (static_padding): ZeroPad2d((1, 1, 1, 1))\n        )\n        (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_se_reduce): Conv2dStaticSamePadding(\n          192, 8, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_se_expand): Conv2dStaticSamePadding(\n          8, 192, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_project_conv): Conv2dStaticSamePadding(\n          192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_swish): MemoryEfficientSwish()\n      )\n      (6): MBConvBlock(\n        (_expand_conv): Conv2dStaticSamePadding(\n          32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_depthwise_conv): Conv2dStaticSamePadding(\n          192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False\n          (static_padding): ZeroPad2d((2, 2, 2, 2))\n        )\n        (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_se_reduce): Conv2dStaticSamePadding(\n          192, 8, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_se_expand): Conv2dStaticSamePadding(\n          8, 192, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_project_conv): Conv2dStaticSamePadding(\n          192, 56, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn2): BatchNorm2d(56, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_swish): MemoryEfficientSwish()\n      )\n      (7-9): 3 x MBConvBlock(\n        (_expand_conv): Conv2dStaticSamePadding(\n          56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn0): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_depthwise_conv): Conv2dStaticSamePadding(\n          336, 336, kernel_size=(5, 5), stride=(1, 1), groups=336, bias=False\n          (static_padding): ZeroPad2d((2, 2, 2, 2))\n        )\n        (_bn1): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_se_reduce): Conv2dStaticSamePadding(\n          336, 14, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_se_expand): Conv2dStaticSamePadding(\n          14, 336, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_project_conv): Conv2dStaticSamePadding(\n          336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn2): BatchNorm2d(56, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_swish): MemoryEfficientSwish()\n      )\n      (10): MBConvBlock(\n        (_expand_conv): Conv2dStaticSamePadding(\n          56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn0): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_depthwise_conv): Conv2dStaticSamePadding(\n          336, 336, kernel_size=(3, 3), stride=[2, 2], groups=336, bias=False\n          (static_padding): ZeroPad2d((0, 1, 0, 1))\n        )\n        (_bn1): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_se_reduce): Conv2dStaticSamePadding(\n          336, 14, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_se_expand): Conv2dStaticSamePadding(\n          14, 336, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_project_conv): Conv2dStaticSamePadding(\n          336, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_swish): MemoryEfficientSwish()\n      )\n      (11-15): 5 x MBConvBlock(\n        (_expand_conv): Conv2dStaticSamePadding(\n          112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_depthwise_conv): Conv2dStaticSamePadding(\n          672, 672, kernel_size=(3, 3), stride=(1, 1), groups=672, bias=False\n          (static_padding): ZeroPad2d((1, 1, 1, 1))\n        )\n        (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_se_reduce): Conv2dStaticSamePadding(\n          672, 28, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_se_expand): Conv2dStaticSamePadding(\n          28, 672, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_project_conv): Conv2dStaticSamePadding(\n          672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_swish): MemoryEfficientSwish()\n      )\n      (16): MBConvBlock(\n        (_expand_conv): Conv2dStaticSamePadding(\n          112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_depthwise_conv): Conv2dStaticSamePadding(\n          672, 672, kernel_size=(5, 5), stride=[1, 1], groups=672, bias=False\n          (static_padding): ZeroPad2d((2, 2, 2, 2))\n        )\n        (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_se_reduce): Conv2dStaticSamePadding(\n          672, 28, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_se_expand): Conv2dStaticSamePadding(\n          28, 672, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_project_conv): Conv2dStaticSamePadding(\n          672, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_swish): MemoryEfficientSwish()\n      )\n      (17-21): 5 x MBConvBlock(\n        (_expand_conv): Conv2dStaticSamePadding(\n          160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_depthwise_conv): Conv2dStaticSamePadding(\n          960, 960, kernel_size=(5, 5), stride=(1, 1), groups=960, bias=False\n          (static_padding): ZeroPad2d((2, 2, 2, 2))\n        )\n        (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_se_reduce): Conv2dStaticSamePadding(\n          960, 40, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_se_expand): Conv2dStaticSamePadding(\n          40, 960, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_project_conv): Conv2dStaticSamePadding(\n          960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_swish): MemoryEfficientSwish()\n      )\n      (22): MBConvBlock(\n        (_expand_conv): Conv2dStaticSamePadding(\n          160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_depthwise_conv): Conv2dStaticSamePadding(\n          960, 960, kernel_size=(5, 5), stride=[2, 2], groups=960, bias=False\n          (static_padding): ZeroPad2d((1, 2, 1, 2))\n        )\n        (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_se_reduce): Conv2dStaticSamePadding(\n          960, 40, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_se_expand): Conv2dStaticSamePadding(\n          40, 960, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_project_conv): Conv2dStaticSamePadding(\n          960, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_swish): MemoryEfficientSwish()\n      )\n      (23-29): 7 x MBConvBlock(\n        (_expand_conv): Conv2dStaticSamePadding(\n          272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_depthwise_conv): Conv2dStaticSamePadding(\n          1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n          (static_padding): ZeroPad2d((2, 2, 2, 2))\n        )\n        (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_se_reduce): Conv2dStaticSamePadding(\n          1632, 68, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_se_expand): Conv2dStaticSamePadding(\n          68, 1632, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_project_conv): Conv2dStaticSamePadding(\n          1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_swish): MemoryEfficientSwish()\n      )\n      (30): MBConvBlock(\n        (_expand_conv): Conv2dStaticSamePadding(\n          272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_depthwise_conv): Conv2dStaticSamePadding(\n          1632, 1632, kernel_size=(3, 3), stride=[1, 1], groups=1632, bias=False\n          (static_padding): ZeroPad2d((1, 1, 1, 1))\n        )\n        (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_se_reduce): Conv2dStaticSamePadding(\n          1632, 68, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_se_expand): Conv2dStaticSamePadding(\n          68, 1632, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_project_conv): Conv2dStaticSamePadding(\n          1632, 448, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn2): BatchNorm2d(448, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_swish): MemoryEfficientSwish()\n      )\n      (31): MBConvBlock(\n        (_expand_conv): Conv2dStaticSamePadding(\n          448, 2688, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn0): BatchNorm2d(2688, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_depthwise_conv): Conv2dStaticSamePadding(\n          2688, 2688, kernel_size=(3, 3), stride=(1, 1), groups=2688, bias=False\n          (static_padding): ZeroPad2d((1, 1, 1, 1))\n        )\n        (_bn1): BatchNorm2d(2688, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_se_reduce): Conv2dStaticSamePadding(\n          2688, 112, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_se_expand): Conv2dStaticSamePadding(\n          112, 2688, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_project_conv): Conv2dStaticSamePadding(\n          2688, 448, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn2): BatchNorm2d(448, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_swish): MemoryEfficientSwish()\n      )\n    )\n    (_conv_head): Conv2dStaticSamePadding(\n      448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False\n      (static_padding): Identity()\n    )\n    (_bn1): BatchNorm2d(1792, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n    (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n    (_dropout): Dropout(p=0.4, inplace=False)\n    (_swish): MemoryEfficientSwish()\n  )\n  (decoder): UnetPlusPlusDecoder(\n    (center): Identity()\n    (blocks): ModuleDict(\n      (x_0_0): DecoderBlock(\n        (conv1): Conv2dReLU(\n          (0): Conv2d(608, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (attention1): Attention(\n          (attention): Identity()\n        )\n        (conv2): Conv2dReLU(\n          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (attention2): Attention(\n          (attention): Identity()\n        )\n      )\n      (x_0_1): DecoderBlock(\n        (conv1): Conv2dReLU(\n          (0): Conv2d(368, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (attention1): Attention(\n          (attention): Identity()\n        )\n        (conv2): Conv2dReLU(\n          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (attention2): Attention(\n          (attention): Identity()\n        )\n      )\n      (x_1_1): DecoderBlock(\n        (conv1): Conv2dReLU(\n          (0): Conv2d(216, 56, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (attention1): Attention(\n          (attention): Identity()\n        )\n        (conv2): Conv2dReLU(\n          (0): Conv2d(56, 56, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (attention2): Attention(\n          (attention): Identity()\n        )\n      )\n      (x_0_2): DecoderBlock(\n        (conv1): Conv2dReLU(\n          (0): Conv2d(224, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (attention1): Attention(\n          (attention): Identity()\n        )\n        (conv2): Conv2dReLU(\n          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (attention2): Attention(\n          (attention): Identity()\n        )\n      )\n      (x_1_2): DecoderBlock(\n        (conv1): Conv2dReLU(\n          (0): Conv2d(120, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (attention1): Attention(\n          (attention): Identity()\n        )\n        (conv2): Conv2dReLU(\n          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (attention2): Attention(\n          (attention): Identity()\n        )\n      )\n      (x_2_2): DecoderBlock(\n        (conv1): Conv2dReLU(\n          (0): Conv2d(88, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (attention1): Attention(\n          (attention): Identity()\n        )\n        (conv2): Conv2dReLU(\n          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (attention2): Attention(\n          (attention): Identity()\n        )\n      )\n      (x_0_3): DecoderBlock(\n        (conv1): Conv2dReLU(\n          (0): Conv2d(256, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (attention1): Attention(\n          (attention): Identity()\n        )\n        (conv2): Conv2dReLU(\n          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (attention2): Attention(\n          (attention): Identity()\n        )\n      )\n      (x_1_3): DecoderBlock(\n        (conv1): Conv2dReLU(\n          (0): Conv2d(176, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (attention1): Attention(\n          (attention): Identity()\n        )\n        (conv2): Conv2dReLU(\n          (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (attention2): Attention(\n          (attention): Identity()\n        )\n      )\n      (x_2_3): DecoderBlock(\n        (conv1): Conv2dReLU(\n          (0): Conv2d(128, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (attention1): Attention(\n          (attention): Identity()\n        )\n        (conv2): Conv2dReLU(\n          (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (attention2): Attention(\n          (attention): Identity()\n        )\n      )\n      (x_3_3): DecoderBlock(\n        (conv1): Conv2dReLU(\n          (0): Conv2d(80, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (attention1): Attention(\n          (attention): Identity()\n        )\n        (conv2): Conv2dReLU(\n          (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (attention2): Attention(\n          (attention): Identity()\n        )\n      )\n      (x_0_4): DecoderBlock(\n        (conv1): Conv2dReLU(\n          (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (attention1): Attention(\n          (attention): Identity()\n        )\n        (conv2): Conv2dReLU(\n          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (attention2): Attention(\n          (attention): Identity()\n        )\n      )\n    )\n  )\n  (segmentation_head): SegmentationHead(\n    (0): Conv2d(16, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): Identity()\n    (2): Activation(\n      (activation): Identity()\n    )\n  )\n)"
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = 'efficientnet-b4'\n",
    "model = smp.UnetPlusPlus(encoder_name=model_name, encoder_weights='imagenet', in_channels=3, classes=1)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3a2be830",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T16:47:31.301671700Z",
     "start_time": "2024-07-08T16:47:31.155157300Z"
    }
   },
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "learning_rate = 0.001\n",
    "optimizer = optim.Adamax(model.parameters(), lr=learning_rate)\n",
    "# criterion = nn.BCEWithLogitsLoss()D\n",
    "#criterion = smp.losses.JaccardLoss(mode='binary')\n",
    "criterion = smp.losses.DiceLoss(mode='binary')\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "GmF0kc5R2RAG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "GmF0kc5R2RAG",
    "outputId": "dca52f72-a6a2-4f53-a85f-9b755c948755",
    "ExecuteTime": {
     "end_time": "2024-07-08T18:28:32.661365100Z",
     "start_time": "2024-07-08T16:47:32.932327100Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 160/160 [05:34<00:00,  2.09s/it]\n",
      "100%|██████████| 18/18 [00:06<00:00,  2.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: Train Loss: 0.6655297033488751, Val Loss: 0.1611619492371877, IoU: 0.009873733079681793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 160/160 [05:25<00:00,  2.03s/it]\n",
      "100%|██████████| 18/18 [00:05<00:00,  3.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20: Train Loss: 0.1037994958460331, Val Loss: 0.08746776315901014, IoU: 0.009873733079681793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 160/160 [05:26<00:00,  2.04s/it]\n",
      "100%|██████████| 18/18 [00:05<00:00,  3.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20: Train Loss: 0.0786598727107048, Val Loss: 0.07612851593229505, IoU: 0.009873733079681793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 160/160 [05:02<00:00,  1.89s/it]\n",
      "100%|██████████| 18/18 [00:04<00:00,  3.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20: Train Loss: 0.07017507255077363, Val Loss: 0.07509666350152758, IoU: 0.009873733079681793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 160/160 [04:50<00:00,  1.81s/it]\n",
      "100%|██████████| 18/18 [00:04<00:00,  3.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20: Train Loss: 0.06554261855781078, Val Loss: 0.06854008634885152, IoU: 0.009873733079681793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 160/160 [04:50<00:00,  1.82s/it]\n",
      "100%|██████████| 18/18 [00:04<00:00,  3.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20: Train Loss: 0.060150818526744844, Val Loss: 0.06889272067281935, IoU: 0.009873733079681793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 160/160 [04:52<00:00,  1.83s/it]\n",
      "100%|██████████| 18/18 [00:05<00:00,  3.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20: Train Loss: 0.056124156713485716, Val Loss: 0.06713287697898017, IoU: 0.009873733079681793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 160/160 [05:00<00:00,  1.88s/it]\n",
      "100%|██████████| 18/18 [00:04<00:00,  3.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20: Train Loss: 0.05447532683610916, Val Loss: 0.0628377033604516, IoU: 0.009873733079681793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 160/160 [04:48<00:00,  1.80s/it]\n",
      "100%|██████████| 18/18 [00:04<00:00,  3.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20: Train Loss: 0.053371640667319295, Val Loss: 0.06098474727736579, IoU: 0.009873733079681793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 160/160 [04:49<00:00,  1.81s/it]\n",
      "100%|██████████| 18/18 [00:04<00:00,  3.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20: Train Loss: 0.050109481811523436, Val Loss: 0.05988759464687771, IoU: 0.009873733079681793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 160/160 [04:48<00:00,  1.80s/it]\n",
      "100%|██████████| 18/18 [00:04<00:00,  3.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20: Train Loss: 0.048653898388147356, Val Loss: 0.0600954360432095, IoU: 0.009873733079681793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 160/160 [04:48<00:00,  1.80s/it]\n",
      "100%|██████████| 18/18 [00:04<00:00,  3.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20: Train Loss: 0.04754554107785225, Val Loss: 0.059036976761288114, IoU: 0.009873733079681793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 160/160 [04:48<00:00,  1.80s/it]\n",
      "100%|██████████| 18/18 [00:04<00:00,  3.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20: Train Loss: 0.047320549562573436, Val Loss: 0.05872093637784322, IoU: 0.009873733079681793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 160/160 [04:56<00:00,  1.85s/it]\n",
      "100%|██████████| 18/18 [00:04<00:00,  3.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20: Train Loss: 0.04632802158594131, Val Loss: 0.06070609225167169, IoU: 0.009873733079681793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 160/160 [04:49<00:00,  1.81s/it]\n",
      "100%|██████████| 18/18 [00:04<00:00,  3.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20: Train Loss: 0.04611855931580067, Val Loss: 0.05805457631746928, IoU: 0.009873733079681793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 160/160 [04:49<00:00,  1.81s/it]\n",
      "100%|██████████| 18/18 [00:04<00:00,  3.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20: Train Loss: 0.0454436469823122, Val Loss: 0.05742785334587097, IoU: 0.009873733079681793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 160/160 [04:50<00:00,  1.81s/it]\n",
      "100%|██████████| 18/18 [00:04<00:00,  3.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20: Train Loss: 0.04471349827945233, Val Loss: 0.05813569492763943, IoU: 0.009873733079681793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 160/160 [04:54<00:00,  1.84s/it]\n",
      "100%|██████████| 18/18 [00:04<00:00,  3.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20: Train Loss: 0.04404275044798851, Val Loss: 0.05720631612671746, IoU: 0.009873733079681793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 160/160 [04:54<00:00,  1.84s/it]\n",
      "100%|██████████| 18/18 [00:06<00:00,  2.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20: Train Loss: 0.04358330257236957, Val Loss: 0.05777391791343689, IoU: 0.009873733079681793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 160/160 [05:01<00:00,  1.89s/it]\n",
      "100%|██████████| 18/18 [00:04<00:00,  3.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20: Train Loss: 0.043373212963342664, Val Loss: 0.0568807323773702, IoU: 0.009873733079681793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "model, train_losses, val_losses, iou_test = learning(num_epochs, train_loader, val_loader, model, optimizer, criterion, model_name, scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = smp.UnetPlusPlus('efficientnet-b4', classes=1).to(device)\n",
    "model.load_state_dict(torch.load(\"models/efficientnet-b4_IOU-0.8773694597348415.pth\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-22T18:15:54.040584100Z",
     "start_time": "2024-06-22T18:15:53.206495500Z"
    }
   },
   "id": "5dec4ae6966e5923"
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "def pred(model, loader, device='cuda', size=(544, 928)):\n",
    "    model.eval()\n",
    "    preds, masks = [], []\n",
    "    tfm = transforms.Resize(size)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in tqdm(loader):\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            outs = torch.round(torch.sigmoid(model(xb)))\n",
    "            outs, yb = map(tfm, [outs, yb])\n",
    "            preds.append(outs.cpu().numpy())\n",
    "            masks.append(yb.cpu().numpy())\n",
    "\n",
    "    preds = np.concatenate(preds).squeeze()\n",
    "    masks = np.concatenate(masks).squeeze()\n",
    "    return preds, masks\n",
    "\n",
    "def compute_precision_recall(pred_masks, gt_masks):\n",
    "    pred_flat = pred_masks.flatten().astype(int)\n",
    "    gt_flat = gt_masks.flatten().astype(int)\n",
    "    precision = precision_score(gt_flat, pred_flat)\n",
    "    recall = recall_score(gt_flat, pred_flat)\n",
    "    return precision, recall\n",
    "\n",
    "def compute_iou(pred_masks, gt_masks):\n",
    "    intersection = np.logical_and(pred_masks, gt_masks).sum()\n",
    "    union = np.logical_or(pred_masks, gt_masks).sum()\n",
    "    iou = intersection / union if union != 0 else 0\n",
    "    return iou\n",
    "\n",
    "def validation(model, loader):\n",
    "    preds, masks = pred(model, loader)\n",
    "    precision, recall = compute_precision_recall(preds, masks)\n",
    "    iou = compute_iou(preds, masks)\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"IoU: {iou:.4f}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-08T18:28:47.380419200Z",
     "start_time": "2024-07-08T18:28:47.361420Z"
    }
   },
   "id": "e3fd931b9ebf423b"
  },
  {
   "cell_type": "markdown",
   "id": "YpqqcBlY62Sw",
   "metadata": {
    "id": "YpqqcBlY62Sw"
   },
   "source": [
    "### Evaluation (оценка качества модели)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5bcdf0ea",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "5bcdf0ea",
    "outputId": "878e92cf-335f-4376-ffcd-63f26e424bbc",
    "ExecuteTime": {
     "end_time": "2024-07-08T18:29:29.150885Z",
     "start_time": "2024-07-08T18:28:49.800126Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:06<00:00,  2.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8406\n",
      "Recall: 0.9825\n",
      "IoU: 0.8496\n"
     ]
    }
   ],
   "source": [
    "validation(model, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b358c824",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T18:29:51.497036Z",
     "start_time": "2024-07-08T18:29:45.961672200Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:01<00:01,  2.00s/it]C:\\Users\\pdd\\PycharmProjects\\detect\\venv\\lib\\site-packages\\torch\\nn\\modules\\conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "100%|██████████| 2/2 [00:03<00:00,  1.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8181\n",
      "Recall: 0.9733\n",
      "IoU: 0.8444\n"
     ]
    }
   ],
   "source": [
    "validation(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "8d5edfee96812dd4"
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
