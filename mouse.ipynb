{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "hjO9f4gnIoCf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hjO9f4gnIoCf",
    "outputId": "e789306e-f32e-4843-e621-b7742b27d293",
    "ExecuteTime": {
     "end_time": "2024-06-22T18:45:33.477772400Z",
     "start_time": "2024-06-22T18:45:33.462772800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import os\n",
    "import cv2\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "I = 8\n",
    "\n",
    "L1 = [0.229, 0.224, 0.225]\n",
    "\n",
    "L = [0.485, 0.456, 0.406]\n",
    "\n",
    "_ = (320, 544)\n",
    "\n",
    "folder_path = \"МЫШИПТУ\"\n",
    "\n",
    "seed_value = 52\n",
    "torch.manual_seed(seed_value)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6abd7b7d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T18:45:34.690722100Z",
     "start_time": "2024-06-22T18:45:34.671724700Z"
    }
   },
   "outputs": [],
   "source": [
    "def augmentation():\n",
    "    path_images = \"МЫШИПТУ/images\"\n",
    "    path_masks = \"МЫШИПТУ/masks\"\n",
    "    image_files = os.listdir(path_images)\n",
    "\n",
    "    selected_files_for_vertical = random.sample(image_files, 564)\n",
    "    selected_files_for_horizontal = random.sample(image_files, 1)\n",
    "\n",
    "    for files, flip_type in [(selected_files_for_vertical, Image.FLIP_LEFT_RIGHT), (selected_files_for_horizontal, Image.FLIP_TOP_BOTTOM)]:\n",
    "        for filename in files:\n",
    "            image = Image.open(os.path.join(path_images, filename))\n",
    "            rotated_image = image.transpose(flip_type)\n",
    "            rotated_image.save(os.path.join(path_images, f'revert_{flip_type}_{filename}'))\n",
    "            image.close()\n",
    "\n",
    "            mask = Image.open(os.path.join(path_masks, filename))\n",
    "            rotated_mask = mask.transpose(flip_type)\n",
    "            rotated_mask.save(os.path.join(path_masks, f'revert_{flip_type}_{filename}'))\n",
    "            mask.close()\n",
    "\n",
    "    return selected_files_for_vertical, selected_files_for_horizontal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "12ef3ad3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T18:47:29.691545100Z",
     "start_time": "2024-06-22T18:47:29.654388Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_csv_files(folder_path, folder):\n",
    "    images = [os.path.join(folder, \"images\", file) for file in os.listdir(os.path.join(folder_path, folder, \"images\"))]\n",
    "    masks = [os.path.join(folder, \"masks\", file) for file in os.listdir(os.path.join(folder_path, folder, \"masks\"))]\n",
    "\n",
    "    csv_file_path = \"train_data.csv\" if folder == \"\" else \"test_data.csv\"\n",
    "    pd.DataFrame({'orig_image': images, 'mask_image': masks}).to_csv(csv_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9b1ab03e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T18:47:30.363120900Z",
     "start_time": "2024-06-22T18:47:30.347116800Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train_data.csv\")\n",
    "test = pd.read_csv(\"test_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Qp8AXKYe1GA0",
   "metadata": {
    "id": "Qp8AXKYe1GA0"
   },
   "source": [
    "### Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "YtAjmVyknkeZ",
   "metadata": {
    "id": "YtAjmVyknkeZ",
    "ExecuteTime": {
     "end_time": "2024-06-22T18:47:36.151645500Z",
     "start_time": "2024-06-22T18:47:36.141644300Z"
    }
   },
   "outputs": [],
   "source": [
    "class ImagesDataset(Dataset):\n",
    "    def __init__(self, folder, data, transform_image, transform_mask):\n",
    "        self.folder = folder\n",
    "        self.data = data.copy()\n",
    "        self.orig_image_paths = [os.path.join(folder, filename) for filename in data['orig_image']]\n",
    "        self.mask_image_paths = [os.path.join(folder, filename) for filename in data['mask_image']]\n",
    "        self.transform_image = transform_image\n",
    "        self.transform_mask = transform_mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        orig_image_path = self.orig_image_paths[idx]\n",
    "        mask_image_path = self.mask_image_paths[idx]\n",
    "\n",
    "        orig_image = Image.open(orig_image_path).convert('RGB')\n",
    "        mask_image = Image.open(mask_image_path).convert('L')\n",
    "\n",
    "        orig_image = self.transform_image(orig_image)\n",
    "        mask_image = self.transform_mask(mask_image)\n",
    "\n",
    "        return orig_image, mask_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "QYSoz-zi1dxx",
   "metadata": {
    "id": "QYSoz-zi1dxx",
    "ExecuteTime": {
     "end_time": "2024-06-22T18:48:14.241557300Z",
     "start_time": "2024-06-22T18:48:14.219556700Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train, val = train_test_split(train_df, test_size=0.1, random_state=42)\n",
    "\n",
    "# Define common parameters\n",
    "SIZE = _\n",
    "MEAN = L\n",
    "STD = L1\n",
    "BATCH_SIZE = I\n",
    "\n",
    "transform_image = transforms.Compose([\n",
    "    transforms.Resize(SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=MEAN, std=STD)\n",
    "])\n",
    "\n",
    "transform_mask = transforms.Compose([\n",
    "    transforms.Resize(SIZE),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "def create_loader(dataset, batch_size, shuffle):\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "train_dataset = ImagesDataset(folder_path, train, transform_image, transform_mask)\n",
    "val_dataset = ImagesDataset(folder_path, val, transform_image, transform_mask)\n",
    "test_dataset = ImagesDataset(folder_path, test, transform_image, transform_mask)\n",
    "\n",
    "train_loader = create_loader(train_dataset, BATCH_SIZE, shuffle=True)\n",
    "val_loader = create_loader(val_dataset, BATCH_SIZE, shuffle=False)\n",
    "test_loader = create_loader(test_dataset, BATCH_SIZE, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rrEV7VFN1_60",
   "metadata": {
    "id": "rrEV7VFN1_60"
   },
   "source": [
    "### Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "sDeneMzs7XOP",
   "metadata": {
    "id": "sDeneMzs7XOP",
    "ExecuteTime": {
     "end_time": "2024-06-22T18:48:17.952761300Z",
     "start_time": "2024-06-22T18:48:17.932762700Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(epochs, train_loader, val_loader, model, optimizer, criterion, scheduler=None, device='cuda'):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for xb, yb in tqdm(train_loader):\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(model(xb), yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in tqdm(val_loader):\n",
    "                loss = criterion(model(xb.to(device)), yb.to(device))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "l12xJx4g2G4w",
   "metadata": {
    "id": "l12xJx4g2G4w"
   },
   "source": [
    "### Экспериме"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9206a08b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T18:48:23.987485800Z",
     "start_time": "2024-06-22T18:48:23.688926100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "UnetPlusPlus(\n  (encoder): EfficientNetEncoder(\n    (_conv_stem): Conv2dStaticSamePadding(\n      3, 48, kernel_size=(3, 3), stride=(2, 2), bias=False\n      (static_padding): ZeroPad2d((0, 1, 0, 1))\n    )\n    (_bn0): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n    (_blocks): ModuleList(\n      (0): MBConvBlock(\n        (_depthwise_conv): Conv2dStaticSamePadding(\n          48, 48, kernel_size=(3, 3), stride=[1, 1], groups=48, bias=False\n          (static_padding): ZeroPad2d((1, 1, 1, 1))\n        )\n        (_bn1): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_se_reduce): Conv2dStaticSamePadding(\n          48, 12, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_se_expand): Conv2dStaticSamePadding(\n          12, 48, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_project_conv): Conv2dStaticSamePadding(\n          48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_swish): MemoryEfficientSwish()\n      )\n      (1): MBConvBlock(\n        (_depthwise_conv): Conv2dStaticSamePadding(\n          24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False\n          (static_padding): ZeroPad2d((1, 1, 1, 1))\n        )\n        (_bn1): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_se_reduce): Conv2dStaticSamePadding(\n          24, 6, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_se_expand): Conv2dStaticSamePadding(\n          6, 24, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_project_conv): Conv2dStaticSamePadding(\n          24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_swish): MemoryEfficientSwish()\n      )\n      (2): MBConvBlock(\n        (_expand_conv): Conv2dStaticSamePadding(\n          24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_depthwise_conv): Conv2dStaticSamePadding(\n          144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False\n          (static_padding): ZeroPad2d((0, 1, 0, 1))\n        )\n        (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_se_reduce): Conv2dStaticSamePadding(\n          144, 6, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_se_expand): Conv2dStaticSamePadding(\n          6, 144, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_project_conv): Conv2dStaticSamePadding(\n          144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_swish): MemoryEfficientSwish()\n      )\n      (3-5): 3 x MBConvBlock(\n        (_expand_conv): Conv2dStaticSamePadding(\n          32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_depthwise_conv): Conv2dStaticSamePadding(\n          192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False\n          (static_padding): ZeroPad2d((1, 1, 1, 1))\n        )\n        (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_se_reduce): Conv2dStaticSamePadding(\n          192, 8, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_se_expand): Conv2dStaticSamePadding(\n          8, 192, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_project_conv): Conv2dStaticSamePadding(\n          192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_swish): MemoryEfficientSwish()\n      )\n      (6): MBConvBlock(\n        (_expand_conv): Conv2dStaticSamePadding(\n          32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_depthwise_conv): Conv2dStaticSamePadding(\n          192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False\n          (static_padding): ZeroPad2d((2, 2, 2, 2))\n        )\n        (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_se_reduce): Conv2dStaticSamePadding(\n          192, 8, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_se_expand): Conv2dStaticSamePadding(\n          8, 192, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_project_conv): Conv2dStaticSamePadding(\n          192, 56, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn2): BatchNorm2d(56, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_swish): MemoryEfficientSwish()\n      )\n      (7-9): 3 x MBConvBlock(\n        (_expand_conv): Conv2dStaticSamePadding(\n          56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn0): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_depthwise_conv): Conv2dStaticSamePadding(\n          336, 336, kernel_size=(5, 5), stride=(1, 1), groups=336, bias=False\n          (static_padding): ZeroPad2d((2, 2, 2, 2))\n        )\n        (_bn1): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_se_reduce): Conv2dStaticSamePadding(\n          336, 14, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_se_expand): Conv2dStaticSamePadding(\n          14, 336, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_project_conv): Conv2dStaticSamePadding(\n          336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn2): BatchNorm2d(56, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_swish): MemoryEfficientSwish()\n      )\n      (10): MBConvBlock(\n        (_expand_conv): Conv2dStaticSamePadding(\n          56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn0): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_depthwise_conv): Conv2dStaticSamePadding(\n          336, 336, kernel_size=(3, 3), stride=[2, 2], groups=336, bias=False\n          (static_padding): ZeroPad2d((0, 1, 0, 1))\n        )\n        (_bn1): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_se_reduce): Conv2dStaticSamePadding(\n          336, 14, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_se_expand): Conv2dStaticSamePadding(\n          14, 336, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_project_conv): Conv2dStaticSamePadding(\n          336, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_swish): MemoryEfficientSwish()\n      )\n      (11-15): 5 x MBConvBlock(\n        (_expand_conv): Conv2dStaticSamePadding(\n          112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_depthwise_conv): Conv2dStaticSamePadding(\n          672, 672, kernel_size=(3, 3), stride=(1, 1), groups=672, bias=False\n          (static_padding): ZeroPad2d((1, 1, 1, 1))\n        )\n        (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_se_reduce): Conv2dStaticSamePadding(\n          672, 28, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_se_expand): Conv2dStaticSamePadding(\n          28, 672, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_project_conv): Conv2dStaticSamePadding(\n          672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_swish): MemoryEfficientSwish()\n      )\n      (16): MBConvBlock(\n        (_expand_conv): Conv2dStaticSamePadding(\n          112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_depthwise_conv): Conv2dStaticSamePadding(\n          672, 672, kernel_size=(5, 5), stride=[1, 1], groups=672, bias=False\n          (static_padding): ZeroPad2d((2, 2, 2, 2))\n        )\n        (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_se_reduce): Conv2dStaticSamePadding(\n          672, 28, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_se_expand): Conv2dStaticSamePadding(\n          28, 672, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_project_conv): Conv2dStaticSamePadding(\n          672, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_swish): MemoryEfficientSwish()\n      )\n      (17-21): 5 x MBConvBlock(\n        (_expand_conv): Conv2dStaticSamePadding(\n          160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_depthwise_conv): Conv2dStaticSamePadding(\n          960, 960, kernel_size=(5, 5), stride=(1, 1), groups=960, bias=False\n          (static_padding): ZeroPad2d((2, 2, 2, 2))\n        )\n        (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_se_reduce): Conv2dStaticSamePadding(\n          960, 40, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_se_expand): Conv2dStaticSamePadding(\n          40, 960, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_project_conv): Conv2dStaticSamePadding(\n          960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_swish): MemoryEfficientSwish()\n      )\n      (22): MBConvBlock(\n        (_expand_conv): Conv2dStaticSamePadding(\n          160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_depthwise_conv): Conv2dStaticSamePadding(\n          960, 960, kernel_size=(5, 5), stride=[2, 2], groups=960, bias=False\n          (static_padding): ZeroPad2d((1, 2, 1, 2))\n        )\n        (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_se_reduce): Conv2dStaticSamePadding(\n          960, 40, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_se_expand): Conv2dStaticSamePadding(\n          40, 960, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_project_conv): Conv2dStaticSamePadding(\n          960, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_swish): MemoryEfficientSwish()\n      )\n      (23-29): 7 x MBConvBlock(\n        (_expand_conv): Conv2dStaticSamePadding(\n          272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_depthwise_conv): Conv2dStaticSamePadding(\n          1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n          (static_padding): ZeroPad2d((2, 2, 2, 2))\n        )\n        (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_se_reduce): Conv2dStaticSamePadding(\n          1632, 68, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_se_expand): Conv2dStaticSamePadding(\n          68, 1632, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_project_conv): Conv2dStaticSamePadding(\n          1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_swish): MemoryEfficientSwish()\n      )\n      (30): MBConvBlock(\n        (_expand_conv): Conv2dStaticSamePadding(\n          272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_depthwise_conv): Conv2dStaticSamePadding(\n          1632, 1632, kernel_size=(3, 3), stride=[1, 1], groups=1632, bias=False\n          (static_padding): ZeroPad2d((1, 1, 1, 1))\n        )\n        (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_se_reduce): Conv2dStaticSamePadding(\n          1632, 68, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_se_expand): Conv2dStaticSamePadding(\n          68, 1632, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_project_conv): Conv2dStaticSamePadding(\n          1632, 448, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn2): BatchNorm2d(448, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_swish): MemoryEfficientSwish()\n      )\n      (31): MBConvBlock(\n        (_expand_conv): Conv2dStaticSamePadding(\n          448, 2688, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn0): BatchNorm2d(2688, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_depthwise_conv): Conv2dStaticSamePadding(\n          2688, 2688, kernel_size=(3, 3), stride=(1, 1), groups=2688, bias=False\n          (static_padding): ZeroPad2d((1, 1, 1, 1))\n        )\n        (_bn1): BatchNorm2d(2688, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_se_reduce): Conv2dStaticSamePadding(\n          2688, 112, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_se_expand): Conv2dStaticSamePadding(\n          112, 2688, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_project_conv): Conv2dStaticSamePadding(\n          2688, 448, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn2): BatchNorm2d(448, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_swish): MemoryEfficientSwish()\n      )\n    )\n    (_conv_head): Conv2dStaticSamePadding(\n      448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False\n      (static_padding): Identity()\n    )\n    (_bn1): BatchNorm2d(1792, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n    (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n    (_dropout): Dropout(p=0.4, inplace=False)\n    (_swish): MemoryEfficientSwish()\n  )\n  (decoder): UnetPlusPlusDecoder(\n    (center): Identity()\n    (blocks): ModuleDict(\n      (x_0_0): DecoderBlock(\n        (conv1): Conv2dReLU(\n          (0): Conv2d(608, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (attention1): Attention(\n          (attention): Identity()\n        )\n        (conv2): Conv2dReLU(\n          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (attention2): Attention(\n          (attention): Identity()\n        )\n      )\n      (x_0_1): DecoderBlock(\n        (conv1): Conv2dReLU(\n          (0): Conv2d(368, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (attention1): Attention(\n          (attention): Identity()\n        )\n        (conv2): Conv2dReLU(\n          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (attention2): Attention(\n          (attention): Identity()\n        )\n      )\n      (x_1_1): DecoderBlock(\n        (conv1): Conv2dReLU(\n          (0): Conv2d(216, 56, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (attention1): Attention(\n          (attention): Identity()\n        )\n        (conv2): Conv2dReLU(\n          (0): Conv2d(56, 56, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (attention2): Attention(\n          (attention): Identity()\n        )\n      )\n      (x_0_2): DecoderBlock(\n        (conv1): Conv2dReLU(\n          (0): Conv2d(224, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (attention1): Attention(\n          (attention): Identity()\n        )\n        (conv2): Conv2dReLU(\n          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (attention2): Attention(\n          (attention): Identity()\n        )\n      )\n      (x_1_2): DecoderBlock(\n        (conv1): Conv2dReLU(\n          (0): Conv2d(120, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (attention1): Attention(\n          (attention): Identity()\n        )\n        (conv2): Conv2dReLU(\n          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (attention2): Attention(\n          (attention): Identity()\n        )\n      )\n      (x_2_2): DecoderBlock(\n        (conv1): Conv2dReLU(\n          (0): Conv2d(88, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (attention1): Attention(\n          (attention): Identity()\n        )\n        (conv2): Conv2dReLU(\n          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (attention2): Attention(\n          (attention): Identity()\n        )\n      )\n      (x_0_3): DecoderBlock(\n        (conv1): Conv2dReLU(\n          (0): Conv2d(256, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (attention1): Attention(\n          (attention): Identity()\n        )\n        (conv2): Conv2dReLU(\n          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (attention2): Attention(\n          (attention): Identity()\n        )\n      )\n      (x_1_3): DecoderBlock(\n        (conv1): Conv2dReLU(\n          (0): Conv2d(176, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (attention1): Attention(\n          (attention): Identity()\n        )\n        (conv2): Conv2dReLU(\n          (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (attention2): Attention(\n          (attention): Identity()\n        )\n      )\n      (x_2_3): DecoderBlock(\n        (conv1): Conv2dReLU(\n          (0): Conv2d(128, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (attention1): Attention(\n          (attention): Identity()\n        )\n        (conv2): Conv2dReLU(\n          (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (attention2): Attention(\n          (attention): Identity()\n        )\n      )\n      (x_3_3): DecoderBlock(\n        (conv1): Conv2dReLU(\n          (0): Conv2d(80, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (attention1): Attention(\n          (attention): Identity()\n        )\n        (conv2): Conv2dReLU(\n          (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (attention2): Attention(\n          (attention): Identity()\n        )\n      )\n      (x_0_4): DecoderBlock(\n        (conv1): Conv2dReLU(\n          (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (attention1): Attention(\n          (attention): Identity()\n        )\n        (conv2): Conv2dReLU(\n          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (attention2): Attention(\n          (attention): Identity()\n        )\n      )\n    )\n  )\n  (segmentation_head): SegmentationHead(\n    (0): Conv2d(16, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): Identity()\n    (2): Activation(\n      (activation): Identity()\n    )\n  )\n)"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = 'efficientnet-b4'\n",
    "model = smp.UnetPlusPlus(encoder_name=model_name, encoder_weights='imagenet', in_channels=3, classes=1)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3a2be830",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T18:48:28.199687600Z",
     "start_time": "2024-06-22T18:48:28.187498700Z"
    }
   },
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "learning_rate = 0.001\n",
    "optimizer = optim.Adamax(model.parameters(), lr=learning_rate)\n",
    "criterion = smp.losses.DiceLoss(mode='binary')\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "GmF0kc5R2RAG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "GmF0kc5R2RAG",
    "outputId": "dca52f72-a6a2-4f53-a85f-9b755c948755",
    "ExecuteTime": {
     "end_time": "2024-06-22T18:50:02.291608600Z",
     "start_time": "2024-06-22T18:48:29.086335800Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 13/160 [01:33<17:33,  7.16s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[66], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m num_epochs \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m20\u001B[39m\n\u001B[1;32m----> 2\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnum_epochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[43m                                                        \u001B[49m\u001B[43mscheduler\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[63], line 8\u001B[0m, in \u001B[0;36mtrain_model\u001B[1;34m(epochs, train_loader, val_loader, model, optimizer, criterion, scheduler, device)\u001B[0m\n\u001B[0;32m      6\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m      7\u001B[0m     loss \u001B[38;5;241m=\u001B[39m criterion(model(xb), yb)\n\u001B[1;32m----> 8\u001B[0m     \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      9\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m scheduler:\n",
      "File \u001B[1;32m~\\PycharmProjects\\detect\\venv\\lib\\site-packages\\torch\\_tensor.py:525\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    515\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    517\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[0;32m    518\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    523\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[0;32m    524\u001B[0m     )\n\u001B[1;32m--> 525\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    526\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[0;32m    527\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\detect\\venv\\lib\\site-packages\\torch\\autograd\\__init__.py:267\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    262\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[0;32m    264\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[0;32m    265\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[0;32m    266\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[1;32m--> 267\u001B[0m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    268\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    269\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    270\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    271\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    272\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    273\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    274\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    275\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\detect\\venv\\lib\\site-packages\\torch\\autograd\\graph.py:744\u001B[0m, in \u001B[0;36m_engine_run_backward\u001B[1;34m(t_outputs, *args, **kwargs)\u001B[0m\n\u001B[0;32m    742\u001B[0m     unregister_hooks \u001B[38;5;241m=\u001B[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[0;32m    743\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 744\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m Variable\u001B[38;5;241m.\u001B[39m_execution_engine\u001B[38;5;241m.\u001B[39mrun_backward(  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[0;32m    745\u001B[0m         t_outputs, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[0;32m    746\u001B[0m     )  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[0;32m    747\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    748\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "model = train_model(num_epochs, train_loader, val_loader, model, optimizer, criterion,\n",
    "                                                        scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = smp.UnetPlusPlus('efficientnet-b4', classes=1).to(device)\n",
    "model.load_state_dict(torch.load(\"models/efficientnet-b4_IOU-0.8773694597348415.pth\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-22T18:15:54.040584100Z",
     "start_time": "2024-06-22T18:15:53.206495500Z"
    }
   },
   "id": "5dec4ae6966e5923"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "def predict_masks(model, loader, device='cuda', size=(544, 928)):\n",
    "    model.eval()\n",
    "    predicted_masks, ground_truth_masks = [], []\n",
    "    transform = transforms.Resize(size)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in tqdm(loader):\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "            outputs = torch.round(torch.sigmoid(model(x_batch)))\n",
    "            outputs, y_batch = map(transform, [outputs, y_batch])\n",
    "            predicted_masks.append(outputs.cpu().numpy())\n",
    "            ground_truth_masks.append(y_batch.cpu().numpy())\n",
    "\n",
    "    predicted_masks = np.concatenate(predicted_masks).squeeze()\n",
    "    ground_truth_masks = np.concatenate(ground_truth_masks).squeeze()\n",
    "    return predicted_masks, ground_truth_masks\n",
    "\n",
    "def calculate_precision_recall(predicted_masks, ground_truth_masks):\n",
    "    pred_flat = predicted_masks.flatten().astype(int)\n",
    "    gt_flat = ground_truth_masks.flatten().astype(int)\n",
    "    precision = precision_score(gt_flat, pred_flat)\n",
    "    recall = recall_score(gt_flat, pred_flat)\n",
    "    return precision, recall\n",
    "\n",
    "def calculate_iou(predicted_masks, ground_truth_masks):\n",
    "    intersection = np.logical_and(predicted_masks, ground_truth_masks).sum()\n",
    "    union = np.logical_or(predicted_masks, ground_truth_masks).sum()\n",
    "    iou = intersection / union if union != 0 else 0\n",
    "    return iou\n",
    "\n",
    "def validate_model(model, loader):\n",
    "    predicted_masks, ground_truth_masks = predict_masks(model, loader)\n",
    "    precision, recall = calculate_precision_recall(predicted_masks, ground_truth_masks)\n",
    "    iou = calculate_iou(predicted_masks, ground_truth_masks)\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"IoU: {iou:.4f}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-22T18:33:20.091303400Z",
     "start_time": "2024-06-22T18:33:20.049218200Z"
    }
   },
   "id": "e3fd931b9ebf423b"
  },
  {
   "cell_type": "markdown",
   "id": "YpqqcBlY62Sw",
   "metadata": {
    "id": "YpqqcBlY62Sw"
   },
   "source": [
    "### Оценка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5bcdf0ea",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "5bcdf0ea",
    "outputId": "878e92cf-335f-4376-ffcd-63f26e424bbc",
    "ExecuteTime": {
     "end_time": "2024-06-22T18:34:00.176453600Z",
     "start_time": "2024-06-22T18:33:25.804260900Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:04<00:00,  3.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8367\n",
      "Recall: 0.9922\n",
      "IoU: 0.8635\n"
     ]
    }
   ],
   "source": [
    "validate_model(model, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b358c824",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T18:34:34.911971300Z",
     "start_time": "2024-06-22T18:34:32.244566700Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  4.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8223\n",
      "Recall: 0.9762\n",
      "IoU: 0.8488\n"
     ]
    }
   ],
   "source": [
    "validate_model(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "8d5edfee96812dd4"
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
